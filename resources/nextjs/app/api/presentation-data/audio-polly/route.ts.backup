import { NextRequest, NextResponse } from 'next/server';
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
import { PollyClient, SynthesizeSpeechCommand } from '@aws-sdk/client-polly';
import { v4 as uuidv4 } from 'uuid';
import { Readable } from 'stream';

// Initialize AWS clients
const s3Client = new S3Client({
  region: process.env.REGION || 'us-east-1',
  credentials: {
    accessKeyId: process.env.ACCESS_KEY_ID || '',
    secretAccessKey: process.env.SECRET_ACCESS_KEY || '',
  },
});

const pollyClient = new PollyClient({
  region: process.env.REGION || 'us-east-1',
  credentials: {
    accessKeyId: process.env.ACCESS_KEY_ID || '',
    secretAccessKey: process.env.SECRET_ACCESS_KEY || '',
  },
});

interface ScriptData {
  slides: {
    index: number;
    script: string;
  }[];
}

interface PollySpeechMark {
  time: number;
  type: string;
  start: number;
  end: number;
  value: string;
}

async function addSilence(audioBuffer: Buffer, silenceDurationMs: number) {
  // Create silence buffer (44.1kHz sample rate, 16-bit depth, stereo)
  const samplesPerMs = 44.1; // 44.1kHz
  const silenceLength = Math.floor(silenceDurationMs * samplesPerMs) * 4; // *4 for stereo and 16-bit
  const silenceBuffer = Buffer.alloc(silenceLength);
  
  // Combine silence before, audio, and silence after
  return Buffer.concat([
    silenceBuffer,
    audioBuffer,
    silenceBuffer
  ]);
}

function standardizePollyResponse(speechMarks: PollySpeechMark[], text: string, silenceMs: number) {
  const characters = Array.from(text);
  const charactersStartTimesSeconds = new Array(text.length).fill(-1);
  
  let characterTime = 0;
  
  for (let i = 0; i < speechMarks.length; i++) {
    const speechMark = speechMarks[i];
    const nextSpeechMark = speechMarks[i + 1];
    
    let characterDiff;
    let timeDiff;
    
    if (i < speechMarks.length - 1) {
      characterDiff = nextSpeechMark.start - speechMark.start;
      timeDiff = (nextSpeechMark.time - speechMark.time) / 1000;
      characterTime = timeDiff / characterDiff;
    } else {
      characterDiff = text.length - speechMark.start;
    }
    
    let currentTime = speechMark.time / 1000;
    for (let j = 0; j < characterDiff; j++) {
      charactersStartTimesSeconds[speechMark.start + j] = currentTime;
      currentTime += characterTime;
    }
  }

  // Add delay to all times (silenceMs is already in milliseconds, convert to seconds)
  const silenceSeconds = silenceMs / 1000;
  const startTimes = charactersStartTimesSeconds.map(t => 
    Math.round((t + silenceSeconds) * 1000) / 1000
  );
  const endTimes = startTimes.map(t => 
    Math.round((t + 0.008) * 1000) / 1000
  );

  return {
    alignment: {
      characters,
      character_start_times_seconds: startTimes,
      character_end_times_seconds: endTimes
    }
  };
}

async function processSlide(slide: ScriptData['slides'][0], voiceId: string) {
  try {
    // Get speech marks from Polly
    const speechMarksCommand = new SynthesizeSpeechCommand({
      OutputFormat: 'json',
      Text: slide.script,
      VoiceId: voiceId,
      Engine: 'neural',
      SpeechMarkTypes: ['word']
    });

    const speechMarksResponse = await pollyClient.send(speechMarksCommand);
    const speechMarksText = new TextDecoder().decode(await speechMarksResponse.AudioStream?.transformToByteArray());
    const speechMarks: PollySpeechMark[] = speechMarksText
      .trim()
      .split('\n')
      .map(line => JSON.parse(line));

    // Get audio from Polly
    const audioCommand = new SynthesizeSpeechCommand({
      OutputFormat: 'mp3',
      Text: slide.script,
      VoiceId: voiceId,
      Engine: 'neural'
    });

    const audioResponse = await pollyClient.send(audioCommand);
    const audioBuffer = Buffer.from(await audioResponse.AudioStream?.transformToByteArray() || []);

    // Add silence before and after
    const silenceMs = 200;
    const audioWithSilence = await addSilence(audioBuffer, silenceMs);

    // Transform Polly response with adjusted timing
    const transformedResponse = standardizePollyResponse(speechMarks, slide.script, silenceMs);

    // Upload to S3 with modified audio
    const fileId = uuidv4();
    const key = `presentations/audio/${fileId}.mp3`;

    const uploadCommand = new PutObjectCommand({
      Bucket: process.env.S3_BUCKET_NAME,
      Key: key,
      Body: audioWithSilence,
      ContentType: 'audio/mpeg',
    });

    await s3Client.send(uploadCommand);

    return {
      index: slide.index,
      script: slide.script,
      audio_url: `https://${process.env.S3_BUCKET_NAME}.s3.${process.env.REGION}.amazonaws.com/${key}`,
      letter_timing: transformedResponse.alignment
    };
  } catch (error) {
    console.error(`Error processing slide ${slide.index}:`, error);
    return {
      index: slide.index,
      script: slide.script,
      error: 'Failed to generate audio'
    };
  }
}

export async function POST(request: NextRequest) {
  try {
    const data: ScriptData = await request.json();
    const VOICE_ID = "Joanna"; // Default Polly voice

    const audioResults = [];
    
    for (const slide of data.slides) {
      console.log(`Processing slide ${slide.index}`);
      const result = await processSlide(slide, VOICE_ID);
      audioResults.push(result);
    }

    return NextResponse.json({ slides: audioResults });
  } catch (error) {
    console.error('Audio generation error:', error);
    return NextResponse.json(
      { error: 'Failed to generate audio' },
      { status: 500 }
    );
  }
}